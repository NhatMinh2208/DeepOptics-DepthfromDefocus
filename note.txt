using different imageio library ?
fix the dataset train, val
why to calculate D, have to subtract r, d?
why integral -> riemann sum

CHange:
__compute_loss -> compute_loss
self.wavelengths = wavelengths.to(self.wavelengths.device)
mask_size: 8000 -> 1000
r_grid = math.sqrt(2) * self.mask_pitch * (
                torch.arange(-1, self.mask_size // 2 + 1, dtype=torch.double) + 0.5) - >  torch.arange(1,... )

gpu -> cpu
img_size : 256 -> 32
self.full_size = [32, 32]
mask_upsample_factor', type=int, default=10 -> 1
x_prime = self.mask_pitch * torch.arange(1, self.mask_size + 1).reshape(-1, 1, 1, 1)
init_heightmap1d = torch.zeros(self.full_size[0] // 2 // mask_upsample_factor)  # 1D half size (radius)
self.heightmap1d_ = torch.nn.Parameter(init_heightmap1d, requires_grad=requires_grad)


the constant term outside the intergal???



how to crop imageio
crop h?

#self.heightmap1d_ = torch.nn.Parameter(init_heightmap1d, requires_grad=requires_grad)



change:
img_size = 256  -> 512
#in_camera_phase = self.to_sensor_phase_(355)  -> 200
mask : 64 -> 128
focal_length 50e-3 -> 100e-3



The mask and the sensor should have the same physical size (measure by metter) but can have different 
resolution (Parameter)

Test case:
- zeros-phase mask + pinhole
- fully-open circular amplitude mask + normal lens phase mask

i currently use 3 different resolotion coordinates for amp mask, heightmap and sensor. All covert
to sensor dim later for calculation

khi ko co defocus factor,  gia su anh sacg toi lens la dong pha (song song vs nhau) -> gia su anh sach den tu infinity


# infocus f = s, 
          d khong phai vo cuc, 
          z = f.



# de bai: 
          focal_length / f_number = mask_diameter (this feature currently inactive)
          mask: diameter, res -> pitch
          amp + phase mask: cung length, res co the khac nhau
          sensor: length, res tuy y
          sensor2mask_distance tuy y

amp: learnable (2D)
phase <- heightmap (2D)
1D -> high_1D (cubic) -> high_2D (linear)

our implementation focus on the mask length + res, it the important thing.
Imagine everything after the mask, at a distance s, light is go through an
infinity plane. The sensor length and res is only act like a tool to crop that.


problem:
divide depth level
handle d = f
mask_diameter = focal_length / f_number ????? (try to use this)

change:
mask_diameter: 2.4e-3 -> 5e-3


camera can change focal_length va f_number
the smaller the apeture, the longer exposure time (energy is constant)
if we let camera sensor to light, it gonna be destroy



this lens contain different height at each point, thus combine of many lens circular slide (combine of many 
different focal_length) thus it kinda blurrer than traditional lens

note: in this work, the psf is independ on the focal_length like traditional lens. (it will not exactly 
focus at the focal_length)
But we still use focal_length (to estimate sensor_to_lens_distance).
it can be thought like an approximation we want to make, an starting point, such that
we want our camera to be (approximately acting like a camera with focal_length).
so focal_length not really have a meaning in our work(since a heightmap lens combine different focal_length)
, but just an approximation to normal lens
we want the network to learn. the focal_length in the input is like an expected length of many focal_length.